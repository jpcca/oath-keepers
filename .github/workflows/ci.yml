name: CI

on:
    push:
        branches: [main]
    pull_request:
        branches: [main]

jobs:
    lint:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: "Set up Python"
              uses: actions/setup-python@v5
              with:
                  python-version-file: ".python-version"

            - name: Install uv
              uses: astral-sh/setup-uv@v6
              with:
                  activate-environment: true
                  enable-cache: true

            - name: Install dependencies
              run: uv pip install .[dev]

            - name: Run ruff linter
              run: uv run ruff check .

            - name: Run ruff formatter check
              run: uv run ruff format --check .

    test:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: "Set up Python"
              uses: actions/setup-python@v5
              with:
                  python-version-file: ".python-version"

            - name: Install uv
              uses: astral-sh/setup-uv@v6
              with:
                  activate-environment: true
                  enable-cache: true

            - name: Setup cmake
              uses: jwlawson/actions-setup-cmake@v2
              with:
                  cmake-version: "3.26.1"

            # - name: Install build dependencies
            #   run: |
            #       sudo apt-get update -y
            #       sudo apt-get install -y --no-install-recommends ccache git curl wget ca-certificates gcc-12 g++-12 libtcmalloc-minimal4 libnuma-dev ffmpeg libsm6 libxext6 libgl1 jq lsof
            #       sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12

            - name: Build vLLM for CPU
              run: |
                  git clone https://github.com/vllm-project/vllm.git vllm_source
                  cd vllm_source
                  uv pip install -r requirements/cpu-build.txt --torch-backend auto
                  uv pip install -r requirements/cpu.txt --torch-backend auto
                  VLLM_TARGET_DEVICE=cpu python setup.py install

            - name: Install dependencies
              run: uv pip install .[dev]

            - name: Run tests
              run: |
                  export LD_PRELOAD="/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4:$LD_PRELOAD"
                  python oath_keepers/vllm_server.py --model tiny-random/gemma-3 &
                  while ! nc -z localhost 8000; do sleep 1; done
                  uv run pytest
