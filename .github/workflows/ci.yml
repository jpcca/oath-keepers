name: CI

on:
    push:
        branches: [main]
    pull_request:
        branches: [main]

jobs:
    lint:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: "Set up Python"
              uses: actions/setup-python@v5
              with:
                  python-version-file: ".python-version"

            - name: Install uv
              uses: astral-sh/setup-uv@v6
              with:
                  activate-environment: true
                  enable-cache: true

            - name: Install dependencies
              run: uv pip install .[cpu,dev]

            - name: Run ruff linter
              run: uv run ruff check .

            - name: Run ruff formatter check
              run: uv run ruff format --check .

    test:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: "Set up Python"
              uses: actions/setup-python@v5
              with:
                  python-version-file: ".python-version"

            - name: Install uv
              uses: astral-sh/setup-uv@v6
              with:
                  activate-environment: true
                  enable-cache: true

            - name: Build vLLM for CPU
              run: uv run bash vllm-cpu.sh

            - name: Install dependencies
              run: uv pip install .[cpu,dev]

            - name: Run tests
              run: |
                  hf auth login --token ${{ secrets.HUGGINGFACE }} --add-to-git-credential
                  uv run oath_keepers/vllm_server.py --model google/gemma-2b-it &

                  counter=0
                  while ! nc -z localhost 8000; do
                    if [ $counter -ge 60 ]; then
                      echo "Timeout waiting for vLLM server to start on localhost:8000"
                      exit 1
                    fi
                    sleep 1
                    counter=$((counter+1))
                  done

                  uv run pytest
