name: CI

on:
    push:
        branches: [main]
    pull_request:
        branches: [main]

jobs:
    lint:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: "Set up Python"
              uses: actions/setup-python@v5
              with:
                  python-version-file: ".python-version"

            - name: Install uv
              uses: astral-sh/setup-uv@v6
              with:
                  activate-environment: true
                  enable-cache: true

            - name: Install dependencies
              run: uv pip install .[dev]

            - name: Run ruff linter
              run: uv run ruff check .

            - name: Run ruff formatter check
              run: uv run ruff format --check .

    test:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: "Set up Python"
              uses: actions/setup-python@v5
              with:
                  python-version-file: ".python-version"

            - name: Install uv
              uses: astral-sh/setup-uv@v6
              with:
                  activate-environment: true
                  enable-cache: true

            - name: Install build dependencies
              run: |
                  sudo apt-get install -y --no-install-recommends libnuma-dev

            - name: Build vLLM for CPU
              run: |
                  git clone https://github.com/vllm-project/vllm.git vllm_source
                  cd vllm_source
                  uv pip install -r requirements/cpu-build.txt --torch-backend auto --index-strategy unsafe-best-match
                  uv pip install -r requirements/cpu.txt --torch-backend auto --index-strategy unsafe-best-match
                  VLLM_TARGET_DEVICE=cpu python setup.py install
                  cd ..

            - name: Install dependencies
              run: uv pip install .[dev]

            - name: Run tests
              run: |
                  export LD_PRELOAD="/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4:$LD_PRELOAD"
                  python oath_keepers/vllm_server.py --model tiny-random/gemma-3 &
                  while ! nc -z localhost 8000; do sleep 1; done
                  uv run pytest
